### Embedding指什么
-  大模型中，Embedding指的是将输入数据（比如文本、图像、声音等）转换成一个数值向量的过程。向量包含很多维度，每一个维度代表输入数据的某种抽象特征。
-  Embedding讲数据转换成向量表示后，计算机才能更有效地进行处理。

##### 文本Embedding
在NLP（自然语言处理，Natural Language Processing）中，文本embedding指的是将token（可以理解成单位文字或短语）转换成数值向量的过程。这些向量包含了token的各种语义特征（每个token使用向量表示具有很多的维度，每个维度表示某种语义特征，这个维度的值反映了相应特征的强度）。比如，使用词嵌入技术（如Word2Vec或BERT），模型可以将具有**相似意义的词映射到向量空间中的相近位置**。

两个token之间的关系就可以利用两个向量的相似度来衡量（高中知识：余弦相似度是一种方法，在文本分析中，它常用于比较两段文本的语义相似性）。

<img width="526" alt="image" src="https://github.com/user-attachments/assets/559340bf-da0e-48bd-889f-273fe14e3fc4">

如果两个文本的向量化表示在方向上更接近，它们的余弦相似度就更高，这意味着它们在语义上更相似。
