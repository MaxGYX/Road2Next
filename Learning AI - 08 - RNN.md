### RNN（Recurrent Neural Networks递归神经网络）
CNN善于捕获输入数据的特征，但是不能处理前后输入数据之间的关系，也就是说前一个输入和后一个输入是完全没有关系的。而有些任务，必须考虑前后输入数据的关系，比如翻译一段话，输入的单词到底是什么意思依赖前后的语境，这个时候CNN就处理不了了。

RNN是专门设计处理序列数据的神经网络，结构内部包含一个循环结构，能够将前一时刻的输出也作为下一时刻的输入的一部分，因此可以处理序列数据。在处理文本、语音、视频等有时间先后顺序的序列数据时，可以考虑到数据之间的时间依赖关系。

<img width="921" alt="image" src="https://github.com/user-attachments/assets/18106c60-36f4-4e79-b7da-1f4a2cc7f4c9">

**RNN的问题**
在处理输入数据比较长时，容易出现梯度消失或者梯度爆炸的问题。比如梯度消失：

  - 在进行反向传播求导时，当前t时刻隐层输出的梯度包含了**所有后续时刻激活函数导数的乘积**，所以如果t越小、句子越长，同时后续时刻激活函数的导数特别小，累乘之后就会更小，则会出现梯度消失问题；反之，则是梯度爆炸问题。
  - RNN 所谓梯度消失的真正含义是，梯度被近距离梯度主导（即远距离梯度很小），导致模型难以学到远距离的依赖关系。

